{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ff54ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as MK\n",
    "from matplotlib import rcParams\n",
    "from torchsummary import summary\n",
    "import pywt\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "291dc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# def readtxt(folder_path):    \n",
    "#     new_data = []\n",
    "\n",
    "#     for folder_name in os.listdir(folder_path):\n",
    "#         folder_dir = os.path.join(folder_path, folder_name)\n",
    "#         print(folder_name)\n",
    "\n",
    "#         if os.path.isdir(folder_dir):\n",
    "#             for filename in os.listdir(folder_dir):\n",
    "#                 if filename.endswith(\".txt\"):\n",
    "#                     file_path = os.path.join(folder_dir, filename)\n",
    "#                     data = np.loadtxt(file_path)\n",
    "#                     new_data.append(data[:, 1])\n",
    "#     return np.concatenate([a.flatten() for a in new_data])\n",
    "# aa = readtxt(folder_path = r\"F:\\OneDrive\\桌面\\数据\\SO2  分类 - 副本\")\n",
    "# aa,aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "454d8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yy1 = x[250]#画一个看\n",
    "# print(yy1.shape)\n",
    "# xx1 = [i for i in range(421)]#一个光谱样本数据的大小\n",
    "# z1 = np.polyfit(xx1, yy1, 4) # 用4次多项式拟合，可改变多项式阶数\n",
    "# p1 = np.poly1d(z1) #得到多项式系数，按照阶数从高到低排列\n",
    "# print(p1)  #显示多项式\n",
    "# fit = p1(xx1)\n",
    "# plt.plot(xx1, yy1, 'r',label='original values')\n",
    "# plt.plot(xx1, fit, '*',label='polyfit values')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend(loc=1) # 指定图例legend在第一象限\n",
    "# plt.title('polyfitting')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f234e10",
   "metadata": {},
   "source": [
    "DOAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "19dbf11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def koumanbian(shuju):\n",
    "#     xinshuju = []\n",
    "#     for i in shuju:\n",
    "#         zz1 = np.polyfit([i for i in range(len(i))], i, 4) # 拟合\n",
    "#         pp1 = np.poly1d(zz1) \n",
    "#         xinshuju.append(np.log(i/(pp1([i for i in range(len(i))]))))\n",
    "#     return np.array(xinshuju)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "33507c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jj = koumanbian(x)\n",
    "# jj.shape\n",
    "# plt.figure()\n",
    "# plt.plot(jj[93],label='min')\n",
    "# # plt.plot(jj[225],label='mid1')\n",
    "# # plt.plot(jj[270],label='mid2')\n",
    "# # plt.plot(jj[360],label='max')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend(loc=1) \n",
    "# plt.title('cha fen pu')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4a2e59a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 500)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(pd.read_excel(r'F:\\OneDrive\\桌面\\混合气体差分谱.xlsx'))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec83df7",
   "metadata": {},
   "source": [
    "WPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0e61b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructe (shuju):\n",
    "    new_data = []\n",
    "    for i in shuju:\n",
    "        wp = pywt.WaveletPacket(data=i, wavelet='db3', mode='symmetric', maxlevel=3)\n",
    "        nodes = wp.get_level(3, 'freq')\n",
    "        labels = [n.path for n in nodes]\n",
    "        threshold = np.std(i) * np.sqrt(1*np.log(len(i)))\n",
    "        for label in labels:\n",
    "            if wp[label].data is not None and np.abs(wp[label].data).max() < threshold:\n",
    "                wp[label].data.fill(0)\n",
    "        denoised_sig = wp.reconstruct(update=True)\n",
    "        new_data.append(denoised_sig)\n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a4d988d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reconstructe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "af16c127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 3)\n"
     ]
    }
   ],
   "source": [
    "pp = np.ones(100)\n",
    "y1 = pp*0\n",
    "y2 = pp*0\n",
    "y3 = pp*0\n",
    "y4 = pp*0\n",
    "y5 = pp*0\n",
    "y6 = pp*0\n",
    "y7 = pp*0\n",
    "y8 = pp*0\n",
    "y9 = pp*0.1\n",
    "y10 = pp*0.5\n",
    "y11 = pp*6\n",
    "y12 = pp*10\n",
    "y13 = pp*8\n",
    "y14 = pp*2\n",
    "y15 = pp*6\n",
    "y16 = pp*4\n",
    "y17 = pp*0.5\n",
    "y18 = pp*2\n",
    "y19 = pp*0.1\n",
    "y20 = pp*4\n",
    "y21 = pp*0\n",
    "y22 = pp*0\n",
    "y23 = pp*0\n",
    "y24 = pp*0\n",
    "y25 = pp*8\n",
    "y26 = pp*10\n",
    "y27 = pp*6\n",
    "y28 = pp*4\n",
    "y29 = pp*2\n",
    "y30 = pp*0.5\n",
    "y31 = pp*8\n",
    "y32 = pp*10\n",
    "y33 = pp*0.1\n",
    "ySO2 = np.r_[y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,y11,y12,y13,y14,y15,y16,y17,y18,y19,y20,y21,y22,y23,y24,y25,y26,y27,y28,y29,y30,y31,y32,y33]\n",
    "\n",
    "pp = np.ones(100)\n",
    "yy1 = pp*0\n",
    "yy2 = pp*0\n",
    "yy3 = pp*0\n",
    "yy4 = pp*0\n",
    "yy5 = pp*0.1\n",
    "yy6 = pp*0.5\n",
    "yy7 = pp*4\n",
    "yy8 = pp*6\n",
    "yy9 = pp*0\n",
    "yy10 = pp*0\n",
    "yy11 = pp*0\n",
    "yy12 = pp*0\n",
    "yy13 = pp*0.5\n",
    "yy14 = pp*4\n",
    "yy15 = pp*0.1\n",
    "yy16 = pp*2\n",
    "yy17 = pp*0\n",
    "yy18 = pp*0\n",
    "yy19 = pp*0\n",
    "yy20 = pp*0\n",
    "yy21 = pp*6\n",
    "yy22 = pp*10\n",
    "yy23 = pp*2\n",
    "yy24 = pp*8\n",
    "yy25 = pp*2\n",
    "yy26 = pp*8\n",
    "yy27 = pp*10\n",
    "yy28 = pp*10\n",
    "yy29 = pp*0.5\n",
    "yy30 = pp*6\n",
    "yy31 = pp*0.1\n",
    "yy32 = pp*8\n",
    "yy33 = pp*4\n",
    "yCS2 = np.r_[yy1,yy2,yy3,yy4,yy5,yy6,yy7,yy8,yy9,yy10,yy11,yy12,yy13,yy14,yy15,yy16,yy17,yy18,yy19,yy20,yy21,yy22,yy23,yy24,yy25,yy26,yy27,yy28,yy29,yy30,yy31,yy32,yy33]\n",
    "\n",
    "pp = np.ones(100)\n",
    "yyy1 = pp*0.1\n",
    "yyy2 = pp*0.5\n",
    "yyy3 = pp*2\n",
    "yyy4 = pp*8\n",
    "yyy5 = pp*0\n",
    "yyy6 = pp*0\n",
    "yyy7 = pp*0\n",
    "yyy8 = pp*0\n",
    "yyy9 = pp*0\n",
    "yyy10 = pp*0\n",
    "yyy11 = pp*0\n",
    "yyy12 = pp*0\n",
    "yyy13 = pp*0\n",
    "yyy14 = pp*0\n",
    "yyy15 = pp*0\n",
    "yyy16 = pp*0\n",
    "yyy17 = pp*6\n",
    "yyy18 = pp*0.1\n",
    "yyy19 = pp*4\n",
    "yyy20 = pp*10\n",
    "yyy21 = pp*0.5\n",
    "yyy22 = pp*2\n",
    "yyy23 = pp*6\n",
    "yyy24 = pp*4\n",
    "yyy25 = pp*6\n",
    "yyy26 = pp*10\n",
    "yyy27 = pp*8\n",
    "yyy28 = pp*0.5\n",
    "yyy29 = pp*8\n",
    "yyy30 = pp*0.1\n",
    "yyy31 = pp*2\n",
    "yyy32 = pp*4\n",
    "yyy33 = pp*10\n",
    "yNO = np.r_[yyy1,yyy2,yyy3,yyy4,yyy5,yyy6,yyy7,yyy8,yyy9,yyy10,yyy11,yyy12,yyy13,yyy14,yyy15,yyy16,yyy17,yyy18,yyy19,yyy20,yyy21,yyy22,yyy23,yyy24,yyy25,yyy26,yyy27,yyy28,yyy29,yyy30,yyy31,yyy32,yyy33]\n",
    "y = np.c_[ySO2,yCS2,yNO]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2dc01619",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(x,y, test_size = 0.2,random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "557fdb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(2640, 500)\n",
      "Shapes:\n",
      "x_train:(2640, 1, 500)\n",
      "y_train:(2640, 3)\n",
      "\n",
      "x_test:(660, 1, 500)\n",
      "y_test:(660, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train:{x_train.shape}')\n",
    "x_train = np.array(x_train).reshape(x_train.shape[0],1, x_train.shape[1])\n",
    "x_test = np.array(x_test).reshape(x_test.shape[0],1, x_test.shape[1])\n",
    "print(\"Shapes:\\nx_train:%s\\ny_train:%s\\n\" % (x_train.shape, y_train.shape))\n",
    "print(\"x_test:%s\\ny_test:%s\\n\" % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1b7fc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20)   \n",
    "x_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "torch_dataset = Data.TensorDataset(x_train, y_train)    \n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,\n",
    "    batch_size=2640,  # Reduce the batch_size so that the weights can learn adaptively\n",
    "    shuffle=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "695c5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):         \n",
    "    def __init__(self, in_planes, ratio):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Conv1d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv1d(in_planes // ratio, in_planes, 1, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):       \n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4374c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):           \n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__() \n",
    "        assert  kernel_size in (3,7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1 \n",
    "        self.conv1 = nn.Conv1d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out,_ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c4a9cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes=32*3, ratio=8, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x*self.ca(x)\n",
    "        result = out*self.sa(out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f899f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualBlock(epochs, TheNthSample, channels, VisualData):\n",
    "    if epoch == epochs: \n",
    "        for channel in range (0, channels):\n",
    "            plt.subplot(12, 8, channel+1)\n",
    "            plt.figure(1, dpi = 400)\n",
    "            get_data = VisualData[TheNthSample][channel]\n",
    "            get_data = get_data.reshape(-1, 1)\n",
    "            plt.plot(get_data.detach().numpy(),linewidth = 0.5)\n",
    "            plt.xticks([0, 50, 100], fontsize = 5)\n",
    "            plt.yticks(fontsize = 5)\n",
    "            plt.tick_params(axis='x', which='major', width=0.1, length=0.5, pad=0)\n",
    "            plt.tick_params(axis='y', which='major', width=0.1, length=0.5, pad=0)\n",
    "            plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "        legend = plt.legend(['Multi-level spectral features', 'Weighted multi-level spectral features'], fontsize=5, bbox_to_anchor=(-1.9, -1.5), loc='lower center', ncol=2,frameon=False)\n",
    "        plt.savefig ('F:\\\\OneDrive\\\\桌面\\\\zxy.png', dpi=300, facecolor='w', edgecolor='w', orientation='portrait',\n",
    "        format=None, transparent=False, bbox_inches='tight', pad_inches=0.01, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8c94be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 500])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 32, 99]             192\n",
      "         LeakyReLU-2               [-1, 32, 99]               0\n",
      "            Conv1d-3               [-1, 32, 99]             512\n",
      "         LeakyReLU-4               [-1, 32, 99]               0\n",
      "            Conv1d-5               [-1, 32, 99]             992\n",
      "         LeakyReLU-6               [-1, 32, 99]               0\n",
      "            Conv1d-7               [-1, 32, 99]           5,152\n",
      "         LeakyReLU-8               [-1, 32, 99]               0\n",
      "            Conv1d-9               [-1, 32, 99]          15,392\n",
      "        LeakyReLU-10               [-1, 32, 99]               0\n",
      "           Conv1d-11               [-1, 32, 98]          30,752\n",
      "        LeakyReLU-12               [-1, 32, 98]               0\n",
      "           Conv1d-13               [-1, 32, 99]           5,152\n",
      "        LeakyReLU-14               [-1, 32, 99]               0\n",
      "           Conv1d-15               [-1, 32, 99]          15,392\n",
      "        LeakyReLU-16               [-1, 32, 99]               0\n",
      "           Conv1d-17               [-1, 32, 98]          30,752\n",
      "        LeakyReLU-18               [-1, 32, 98]               0\n",
      "AdaptiveAvgPool1d-19                [-1, 96, 1]               0\n",
      "           Conv1d-20                [-1, 12, 1]           1,152\n",
      "             ReLU-21                [-1, 12, 1]               0\n",
      "           Conv1d-22                [-1, 96, 1]           1,152\n",
      "AdaptiveMaxPool1d-23                [-1, 96, 1]               0\n",
      "           Conv1d-24                [-1, 12, 1]           1,152\n",
      "             ReLU-25                [-1, 12, 1]               0\n",
      "           Conv1d-26                [-1, 96, 1]           1,152\n",
      "          Sigmoid-27                [-1, 96, 1]               0\n",
      " ChannelAttention-28                [-1, 96, 1]               0\n",
      "           Conv1d-29                [-1, 1, 99]              14\n",
      "          Sigmoid-30                [-1, 1, 99]               0\n",
      " SpatialAttention-31                [-1, 1, 99]               0\n",
      "             CBAM-32               [-1, 96, 99]               0\n",
      "           Linear-33                  [-1, 128]       1,216,640\n",
      "        LeakyReLU-34                  [-1, 128]               0\n",
      "           Linear-35                   [-1, 64]           8,256\n",
      "        LeakyReLU-36                   [-1, 64]               0\n",
      "           Linear-37                    [-1, 1]              65\n",
      "           Linear-38                  [-1, 128]       1,216,640\n",
      "        LeakyReLU-39                  [-1, 128]               0\n",
      "           Linear-40                   [-1, 64]           8,256\n",
      "        LeakyReLU-41                   [-1, 64]               0\n",
      "           Linear-42                    [-1, 1]              65\n",
      "           Linear-43                  [-1, 128]       1,216,640\n",
      "        LeakyReLU-44                  [-1, 128]               0\n",
      "           Linear-45                   [-1, 64]           8,256\n",
      "        LeakyReLU-46                   [-1, 64]               0\n",
      "           Linear-47                    [-1, 1]              65\n",
      "================================================================\n",
      "Total params: 3,783,793\n",
      "Trainable params: 3,783,793\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 14.43\n",
      "Estimated Total Size (MB): 14.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNN_base(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(CNN_base,self).__init__() \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, padding=5, stride=5, dilation=4)\n",
    "        self.conv2 = nn.Conv1d(1, 32, kernel_size=15, padding=10, stride=5, dilation=2)  \n",
    "        self.conv3 = nn.Conv1d(1, 32, kernel_size=30, padding=25, stride=5, dilation=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(32, 32, kernel_size=5, padding=2, stride=1, dilation=1)\n",
    "        self.conv5 = nn.Conv1d(32, 32, kernel_size=15, padding=7, stride=1, dilation=1)  \n",
    "        self.conv6 = nn.Conv1d(32, 32, kernel_size=30, padding=14, stride=1, dilation=1)\n",
    "        \n",
    "        self.conv7 = nn.Conv1d(32, 32, kernel_size=5, padding=2, stride=1, dilation=1)\n",
    "        self.conv8 = nn.Conv1d(32, 32, kernel_size=15, padding=7, stride=1, dilation=1)  \n",
    "        self.conv9 = nn.Conv1d(32, 32, kernel_size=30, padding=14, stride=1, dilation=1)\n",
    "        \n",
    "        self.mp = nn.MaxPool1d(2)  \n",
    "        self.relu = nn.LeakyReLU()\n",
    "#         self.softmax = nn.Softmax()\n",
    "        self.cbam = CBAM()\n",
    "        self.weights = nn.Parameter(torch.ones(3).float())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(96*99,128),\n",
    "            nn.LeakyReLU() ,  \n",
    "            nn.Linear(128,64),\n",
    "            nn.LeakyReLU() , \n",
    "            nn.Linear(64,1)   )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(96*99,128),\n",
    "            nn.LeakyReLU() ,  \n",
    "            nn.Linear(128,64),\n",
    "            nn.LeakyReLU() , \n",
    "            nn.Linear(64,1)   )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(96*99,128),\n",
    "            nn.LeakyReLU() , \n",
    "            nn.Linear(128,64),\n",
    "            nn.LeakyReLU() , \n",
    "            nn.Linear(64,1)   )\n",
    "                   \n",
    "    def forward(self,x): \n",
    "\n",
    "        out1 = self.relu(self.conv1(x))\n",
    "        out2 = self.relu(self.conv2(x))\n",
    "        out3 = self.relu(self.conv3(x))\n",
    "        outs1 = out1 + out2 + out3\n",
    "        \n",
    "        out1 = self.relu(self.conv4(outs1))\n",
    "        out2 = self.relu(self.conv5(outs1)) \n",
    "        out3 = self.relu(self.conv6(outs1))\n",
    "        out3 = torch.cat([(torch.zeros(out3.shape[0:2]).unsqueeze(-1)),out3],-1)\n",
    "        outs2 = out1 + out2 + out3\n",
    "        \n",
    "        out1 = self.relu(self.conv7(outs2))\n",
    "        out2 = self.relu(self.conv8(outs2))\n",
    "        out3 = self.relu(self.conv9(outs2))\n",
    "        out3 = torch.cat([(torch.zeros(out3.shape[0:2]).unsqueeze(-1)),out3],-1)\n",
    "        outs3 = out1 + out2 + out3\n",
    "        \n",
    "        outs = torch.cat([outs1, outs2, outs3],1)\n",
    "        VisualBlock(epochs = 50, TheNthSample = 52, channels = 96, VisualData = outs)\n",
    "#         if epoch == 100: \n",
    "#             for a in range (0,96):\n",
    "#                 plt.subplot(12,8,a+1)\n",
    "#                 plt.figure(1, dpi=400)\n",
    "#                 ban = outs[50][a]\n",
    "#                 ban = ban.reshape(-1,1)\n",
    "#                 plt.plot(ban.detach().numpy(),linewidth = 0.5)\n",
    "#                 plt.xticks([0,50,100], fontsize=5)\n",
    "#                 plt.yticks( fontsize=5)\n",
    "#                 plt.tick_params(axis='x', which='major', width=0.1, length=0.5, pad=0)\n",
    "#                 plt.tick_params(axis='y', which='major', width=0.1, length=0.5, pad=0)\n",
    "#                 plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "        out = self.cbam(outs)\n",
    "        VisualBlock(epochs = 50, TheNthSample = 52, channels = 96, VisualData = out)\n",
    "#         if epoch == 100: \n",
    "#             for b in range (0,96):\n",
    "#                 plt.subplot(12,8,b+1)\n",
    "#                 plt.figure(1, dpi=400)\n",
    "#                 ban = out[0][b]\n",
    "#                 ban = ban.reshape(-1,1)\n",
    "#                 plt.plot(ban.detach().numpy(),linewidth = 0.5)\n",
    "#                 plt.xticks([0,50,100], fontsize=5)\n",
    "#                 plt.yticks( fontsize=5)\n",
    "#                 plt.tick_params(axis='x', which='major', width=0.1,length=0.5, pad=0)\n",
    "#                 plt.tick_params(axis='y', which='major', width=0.1,length=0.5, pad=0)\n",
    "#             legend = plt.legend(['Multi-level spectral features', 'Weighted multi-level spectral features'], fontsize=5, bbox_to_anchor=(-1.9, -1.5), loc='lower center', ncol=2,frameon=False)\n",
    "#             plt.savefig ('F:\\\\OneDrive\\\\桌面\\\\zxy.png', dpi=300, facecolor='w', edgecolor='w', orientation='portrait', \n",
    "#             format=None, transparent=False, bbox_inches='tight', pad_inches=0.01, metadata=None)\n",
    "        out = out.view(-1, 96 * 99)\n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc1(out)\n",
    "        out3 = self.fc1(out)\n",
    "        return out1, out2, out3\n",
    "from torchsummary import summary\n",
    "summary(CNN_base(),(1,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e56dbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, EPOCHS, criterion):\n",
    "    Loss_all_list = []\n",
    "    weight_all = []\n",
    "    global epoch\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        Loss_list = []\n",
    "        model.train()\n",
    "        weight_sum = torch.zeros(3)\n",
    "        \n",
    "        for inputs,labels in loader:\n",
    "            inputs = torch.Tensor(inputs).float()\n",
    "            inputs.to(device) \n",
    "            optimizer.zero_grad() \n",
    "            output1,output2,output3 = model(inputs)\n",
    "#             model.weights.data = model.softmax(model.weights.data)\n",
    "            loss1 = criterion(output1, labels[:,0].unsqueeze(1)) \n",
    "            loss2 = criterion(output2, labels[:,1].unsqueeze(1))\n",
    "            loss3 = criterion(output3, labels[:,2].unsqueeze(1))\n",
    "            loss = (\n",
    "                (model.weights[0] / torch.sum(model.weights)) * loss1 +\n",
    "                (model.weights[1] / torch.sum(model.weights)) * loss2 +\n",
    "                (model.weights[2] / torch.sum(model.weights)) * loss3 +\n",
    "                (1 / (model.weights[0])) +\n",
    "                (1 / (model.weights[1])) +\n",
    "                (1 / (model.weights[2]))\n",
    "            )\n",
    "            print(model.weights[0]/torch.sum(model.weights),model.weights[1]/torch.sum(model.weights),model.weights[2]/torch.sum(model.weights))\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            weight_sum += (model.weights / torch.sum(model.weights)).detach()\n",
    "            \n",
    "            print('Train Epoch: {}/{}\\tLoss: {:.6f},'.format(\n",
    "                epoch, EPOCHS, loss.item()))\n",
    "            \n",
    "            Loss_list.append(loss.item())\n",
    "        weight_avg = weight_sum / len(loader)  \n",
    "        weight_all.append(weight_avg.numpy())\n",
    "        Loss_all_list.append(np.mean(np.array(Loss_list))) \n",
    "        pd.DataFrame(weight_all).to_excel('F:\\\\OneDrive\\\\桌面\\\\zxy.xlsx')\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch(times)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(np.array(Loss_all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a8a9e943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 1/100\tLoss: 23.192371,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 2/100\tLoss: 22.601753,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 3/100\tLoss: 21.245945,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 4/100\tLoss: 19.783987,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 5/100\tLoss: 17.985893,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 6/100\tLoss: 16.549757,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 7/100\tLoss: 15.368857,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 8/100\tLoss: 15.321920,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 9/100\tLoss: 15.408017,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 10/100\tLoss: 15.380523,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 11/100\tLoss: 15.304822,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 12/100\tLoss: 15.281940,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 13/100\tLoss: 15.129174,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 14/100\tLoss: 15.019519,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 15/100\tLoss: 14.848262,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 16/100\tLoss: 14.589865,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 17/100\tLoss: 14.406787,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3334, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 18/100\tLoss: 14.494402,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3334, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 19/100\tLoss: 14.470902,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3334, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 20/100\tLoss: 13.934134,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3334, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 21/100\tLoss: 14.188464,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3333, grad_fn=<DivBackward0>) tensor(0.3335, grad_fn=<DivBackward0>) tensor(0.3333, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 22/100\tLoss: 13.478264,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3332, grad_fn=<DivBackward0>) tensor(0.3335, grad_fn=<DivBackward0>) tensor(0.3332, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 23/100\tLoss: 13.637464,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3332, grad_fn=<DivBackward0>) tensor(0.3336, grad_fn=<DivBackward0>) tensor(0.3332, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 24/100\tLoss: 13.342169,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3331, grad_fn=<DivBackward0>) tensor(0.3337, grad_fn=<DivBackward0>) tensor(0.3332, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 25/100\tLoss: 13.180014,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3331, grad_fn=<DivBackward0>) tensor(0.3338, grad_fn=<DivBackward0>) tensor(0.3331, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 26/100\tLoss: 13.105699,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3330, grad_fn=<DivBackward0>) tensor(0.3339, grad_fn=<DivBackward0>) tensor(0.3331, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 27/100\tLoss: 13.027454,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3330, grad_fn=<DivBackward0>) tensor(0.3340, grad_fn=<DivBackward0>) tensor(0.3330, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 28/100\tLoss: 13.030846,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3329, grad_fn=<DivBackward0>) tensor(0.3341, grad_fn=<DivBackward0>) tensor(0.3330, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 29/100\tLoss: 12.972055,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3328, grad_fn=<DivBackward0>) tensor(0.3343, grad_fn=<DivBackward0>) tensor(0.3329, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 30/100\tLoss: 13.080554,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3327, grad_fn=<DivBackward0>) tensor(0.3344, grad_fn=<DivBackward0>) tensor(0.3328, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 31/100\tLoss: 12.892155,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3326, grad_fn=<DivBackward0>) tensor(0.3346, grad_fn=<DivBackward0>) tensor(0.3328, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 32/100\tLoss: 12.890322,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3325, grad_fn=<DivBackward0>) tensor(0.3348, grad_fn=<DivBackward0>) tensor(0.3327, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 33/100\tLoss: 12.832086,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3324, grad_fn=<DivBackward0>) tensor(0.3350, grad_fn=<DivBackward0>) tensor(0.3326, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 34/100\tLoss: 12.900968,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3323, grad_fn=<DivBackward0>) tensor(0.3352, grad_fn=<DivBackward0>) tensor(0.3325, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 35/100\tLoss: 12.804501,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3322, grad_fn=<DivBackward0>) tensor(0.3354, grad_fn=<DivBackward0>) tensor(0.3324, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 36/100\tLoss: 12.805720,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3320, grad_fn=<DivBackward0>) tensor(0.3356, grad_fn=<DivBackward0>) tensor(0.3323, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 37/100\tLoss: 12.814571,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3319, grad_fn=<DivBackward0>) tensor(0.3359, grad_fn=<DivBackward0>) tensor(0.3322, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 38/100\tLoss: 12.778332,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3318, grad_fn=<DivBackward0>) tensor(0.3361, grad_fn=<DivBackward0>) tensor(0.3321, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 39/100\tLoss: 12.742119,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3316, grad_fn=<DivBackward0>) tensor(0.3363, grad_fn=<DivBackward0>) tensor(0.3320, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 40/100\tLoss: 12.909621,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3315, grad_fn=<DivBackward0>) tensor(0.3366, grad_fn=<DivBackward0>) tensor(0.3319, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 41/100\tLoss: 12.721710,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3314, grad_fn=<DivBackward0>) tensor(0.3368, grad_fn=<DivBackward0>) tensor(0.3318, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 42/100\tLoss: 12.855785,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3312, grad_fn=<DivBackward0>) tensor(0.3371, grad_fn=<DivBackward0>) tensor(0.3317, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 43/100\tLoss: 12.841617,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3311, grad_fn=<DivBackward0>) tensor(0.3373, grad_fn=<DivBackward0>) tensor(0.3316, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 44/100\tLoss: 12.702101,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3309, grad_fn=<DivBackward0>) tensor(0.3376, grad_fn=<DivBackward0>) tensor(0.3315, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 45/100\tLoss: 12.720044,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3308, grad_fn=<DivBackward0>) tensor(0.3378, grad_fn=<DivBackward0>) tensor(0.3314, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46/100\tLoss: 12.924870,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3307, grad_fn=<DivBackward0>) tensor(0.3381, grad_fn=<DivBackward0>) tensor(0.3313, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 47/100\tLoss: 12.692975,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3305, grad_fn=<DivBackward0>) tensor(0.3383, grad_fn=<DivBackward0>) tensor(0.3312, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 48/100\tLoss: 12.691146,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3304, grad_fn=<DivBackward0>) tensor(0.3386, grad_fn=<DivBackward0>) tensor(0.3310, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 49/100\tLoss: 12.690141,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3302, grad_fn=<DivBackward0>) tensor(0.3388, grad_fn=<DivBackward0>) tensor(0.3309, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 50/100\tLoss: 12.652349,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3301, grad_fn=<DivBackward0>) tensor(0.3391, grad_fn=<DivBackward0>) tensor(0.3308, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 51/100\tLoss: 12.651031,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3300, grad_fn=<DivBackward0>) tensor(0.3393, grad_fn=<DivBackward0>) tensor(0.3307, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 52/100\tLoss: 12.646174,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3298, grad_fn=<DivBackward0>) tensor(0.3395, grad_fn=<DivBackward0>) tensor(0.3306, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 53/100\tLoss: 12.657465,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3297, grad_fn=<DivBackward0>) tensor(0.3398, grad_fn=<DivBackward0>) tensor(0.3305, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 54/100\tLoss: 12.632316,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3296, grad_fn=<DivBackward0>) tensor(0.3400, grad_fn=<DivBackward0>) tensor(0.3304, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 55/100\tLoss: 12.641210,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3294, grad_fn=<DivBackward0>) tensor(0.3402, grad_fn=<DivBackward0>) tensor(0.3303, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 56/100\tLoss: 12.654995,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3293, grad_fn=<DivBackward0>) tensor(0.3405, grad_fn=<DivBackward0>) tensor(0.3302, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 57/100\tLoss: 12.630956,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3292, grad_fn=<DivBackward0>) tensor(0.3407, grad_fn=<DivBackward0>) tensor(0.3301, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 58/100\tLoss: 12.592400,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3290, grad_fn=<DivBackward0>) tensor(0.3410, grad_fn=<DivBackward0>) tensor(0.3300, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 59/100\tLoss: 12.592530,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3289, grad_fn=<DivBackward0>) tensor(0.3412, grad_fn=<DivBackward0>) tensor(0.3299, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 60/100\tLoss: 12.591125,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3288, grad_fn=<DivBackward0>) tensor(0.3414, grad_fn=<DivBackward0>) tensor(0.3298, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 61/100\tLoss: 12.565351,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3287, grad_fn=<DivBackward0>) tensor(0.3417, grad_fn=<DivBackward0>) tensor(0.3297, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 62/100\tLoss: 12.540215,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3285, grad_fn=<DivBackward0>) tensor(0.3419, grad_fn=<DivBackward0>) tensor(0.3296, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 63/100\tLoss: 12.538113,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3284, grad_fn=<DivBackward0>) tensor(0.3421, grad_fn=<DivBackward0>) tensor(0.3295, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 64/100\tLoss: 12.517027,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3283, grad_fn=<DivBackward0>) tensor(0.3423, grad_fn=<DivBackward0>) tensor(0.3294, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 65/100\tLoss: 12.527672,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3281, grad_fn=<DivBackward0>) tensor(0.3426, grad_fn=<DivBackward0>) tensor(0.3293, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 66/100\tLoss: 12.556130,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3280, grad_fn=<DivBackward0>) tensor(0.3428, grad_fn=<DivBackward0>) tensor(0.3292, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 67/100\tLoss: 12.494475,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3279, grad_fn=<DivBackward0>) tensor(0.3430, grad_fn=<DivBackward0>) tensor(0.3291, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 68/100\tLoss: 12.492268,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3278, grad_fn=<DivBackward0>) tensor(0.3433, grad_fn=<DivBackward0>) tensor(0.3290, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 69/100\tLoss: 12.499771,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3277, grad_fn=<DivBackward0>) tensor(0.3435, grad_fn=<DivBackward0>) tensor(0.3288, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 70/100\tLoss: 12.493378,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3275, grad_fn=<DivBackward0>) tensor(0.3437, grad_fn=<DivBackward0>) tensor(0.3287, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 71/100\tLoss: 12.463250,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3274, grad_fn=<DivBackward0>) tensor(0.3440, grad_fn=<DivBackward0>) tensor(0.3286, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 72/100\tLoss: 12.456786,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3273, grad_fn=<DivBackward0>) tensor(0.3442, grad_fn=<DivBackward0>) tensor(0.3285, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 73/100\tLoss: 12.525337,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3272, grad_fn=<DivBackward0>) tensor(0.3444, grad_fn=<DivBackward0>) tensor(0.3284, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 74/100\tLoss: 12.438637,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3270, grad_fn=<DivBackward0>) tensor(0.3446, grad_fn=<DivBackward0>) tensor(0.3283, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 75/100\tLoss: 12.492068,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3269, grad_fn=<DivBackward0>) tensor(0.3449, grad_fn=<DivBackward0>) tensor(0.3282, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 76/100\tLoss: 12.455646,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3268, grad_fn=<DivBackward0>) tensor(0.3451, grad_fn=<DivBackward0>) tensor(0.3281, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 77/100\tLoss: 12.571572,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3267, grad_fn=<DivBackward0>) tensor(0.3453, grad_fn=<DivBackward0>) tensor(0.3280, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 78/100\tLoss: 12.413770,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3266, grad_fn=<DivBackward0>) tensor(0.3456, grad_fn=<DivBackward0>) tensor(0.3279, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 79/100\tLoss: 12.509415,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3264, grad_fn=<DivBackward0>) tensor(0.3458, grad_fn=<DivBackward0>) tensor(0.3278, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 80/100\tLoss: 12.535381,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3263, grad_fn=<DivBackward0>) tensor(0.3460, grad_fn=<DivBackward0>) tensor(0.3277, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 81/100\tLoss: 12.434510,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3262, grad_fn=<DivBackward0>) tensor(0.3462, grad_fn=<DivBackward0>) tensor(0.3275, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 82/100\tLoss: 12.490862,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3261, grad_fn=<DivBackward0>) tensor(0.3465, grad_fn=<DivBackward0>) tensor(0.3274, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 83/100\tLoss: 12.491075,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3260, grad_fn=<DivBackward0>) tensor(0.3467, grad_fn=<DivBackward0>) tensor(0.3273, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 84/100\tLoss: 12.478559,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3259, grad_fn=<DivBackward0>) tensor(0.3469, grad_fn=<DivBackward0>) tensor(0.3272, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 85/100\tLoss: 12.488554,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3257, grad_fn=<DivBackward0>) tensor(0.3471, grad_fn=<DivBackward0>) tensor(0.3271, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 86/100\tLoss: 12.439195,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3256, grad_fn=<DivBackward0>) tensor(0.3474, grad_fn=<DivBackward0>) tensor(0.3270, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 87/100\tLoss: 12.632990,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3255, grad_fn=<DivBackward0>) tensor(0.3476, grad_fn=<DivBackward0>) tensor(0.3269, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 88/100\tLoss: 12.360135,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3254, grad_fn=<DivBackward0>) tensor(0.3478, grad_fn=<DivBackward0>) tensor(0.3268, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 89/100\tLoss: 12.503222,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3253, grad_fn=<DivBackward0>) tensor(0.3480, grad_fn=<DivBackward0>) tensor(0.3267, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 90/100\tLoss: 12.394250,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3252, grad_fn=<DivBackward0>) tensor(0.3482, grad_fn=<DivBackward0>) tensor(0.3266, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 91/100\tLoss: 12.554985,\n",
      "torch.Size([2640, 1, 500])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3251, grad_fn=<DivBackward0>) tensor(0.3484, grad_fn=<DivBackward0>) tensor(0.3265, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 92/100\tLoss: 12.363527,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3250, grad_fn=<DivBackward0>) tensor(0.3487, grad_fn=<DivBackward0>) tensor(0.3264, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 93/100\tLoss: 12.560401,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3249, grad_fn=<DivBackward0>) tensor(0.3489, grad_fn=<DivBackward0>) tensor(0.3263, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 94/100\tLoss: 12.343999,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3248, grad_fn=<DivBackward0>) tensor(0.3491, grad_fn=<DivBackward0>) tensor(0.3262, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 95/100\tLoss: 12.533974,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3247, grad_fn=<DivBackward0>) tensor(0.3493, grad_fn=<DivBackward0>) tensor(0.3261, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 96/100\tLoss: 12.376138,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3246, grad_fn=<DivBackward0>) tensor(0.3495, grad_fn=<DivBackward0>) tensor(0.3260, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 97/100\tLoss: 12.443357,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3245, grad_fn=<DivBackward0>) tensor(0.3497, grad_fn=<DivBackward0>) tensor(0.3259, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 98/100\tLoss: 12.389498,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3244, grad_fn=<DivBackward0>) tensor(0.3499, grad_fn=<DivBackward0>) tensor(0.3257, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 99/100\tLoss: 12.356766,\n",
      "torch.Size([2640, 1, 500])\n",
      "tensor(0.3243, grad_fn=<DivBackward0>) tensor(0.3501, grad_fn=<DivBackward0>) tensor(0.3256, grad_fn=<DivBackward0>)\n",
      "Train Epoch: 100/100\tLoss: 12.362454,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CNN_base()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "EPOCHS = 100\n",
    "train(model, optimizer, EPOCHS, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x_test, y_test):\n",
    "    preds1 = []\n",
    "    preds2 = []\n",
    "    preds3 = [] \n",
    "    y_true1 = []\n",
    "    y_true2 = []\n",
    "    y_true3 = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():       \n",
    "        x_test = torch.Tensor(x_test).float()\n",
    "        y_test = torch.Tensor(y_test).float()\n",
    "        y_test = y_test.squeeze()\n",
    "        outputs1,outputs2,outputs3 = model(x_test) \n",
    "        detached_pred1 = outputs1.detach().cpu().numpy()\n",
    "        detached_pred2 = outputs2.detach().cpu().numpy()\n",
    "        detached_pred3 = outputs3.detach().cpu().numpy()       \n",
    "        detached_label = y_test.detach().cpu().numpy()\n",
    "        for f in range(0, len(detached_label)):\n",
    "            preds1.append(detached_pred1[f])\n",
    "            preds2.append(detached_pred2[f])\n",
    "            preds3.append(detached_pred3[f])\n",
    "            y_true1.append(detached_label[f][0])\n",
    "            y_true2.append(detached_label[f][1])\n",
    "            y_true3.append(detached_label[f][2])\n",
    "        mse = MK.mean_squared_error(y_true1, preds1)\n",
    "        r2 = MK.r2_score(y_true1, preds1)\n",
    "        print('SO2 MSE:',mse)\n",
    "        print('SO2 R2:',r2) \n",
    "        MSE = MK.mean_squared_error(y_true2, preds2)\n",
    "        R2 = MK.r2_score(y_true2, preds2)\n",
    "        print('CS2 MSE:',MSE)\n",
    "        print('CS2 R2:',R2)  \n",
    "        MMSE = MK.mean_squared_error(y_true3, preds3)\n",
    "        RR2 = MK.r2_score(y_true3, preds3)\n",
    "        print('NO MSE:',MMSE)\n",
    "        print('NO R2:',RR2) \n",
    "        sor = np.argsort(y_test[:,0],axis=0)\n",
    "        sor1 = np.argsort(y_test[:,1],axis=0)\n",
    "        sor2 = np.argsort(y_test[:,2],axis=0)\n",
    "        x_ = range(len(sor))\n",
    "        plt.figure(1)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.scatter(x_, outputs1[sor])\n",
    "        plt.scatter(x_,y_test[:,0][sor])\n",
    "        legend = plt.legend(['pre', 'act'],fontsize=20)\n",
    "        plt.xlabel('Number of data groups',fontsize=20)\n",
    "        plt.ylabel('$\\mathregular{SO_2}$ concentration (ppm)',fontsize=20)\n",
    "        plt.figure(2)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.scatter(x_, outputs2[sor1])\n",
    "        plt.scatter(x_,y_test[:,1][sor1])\n",
    "        legend = plt.legend(['pre', 'act'],fontsize=20)\n",
    "        plt.xlabel('Number of data groups',fontsize=20)\n",
    "        plt.ylabel('$\\mathregular{CS_2}$ concentration (ppm)',fontsize=20)\n",
    "        plt.figure(3)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.scatter(x_, outputs3[sor2])\n",
    "        plt.scatter(x_,y_test[:,2][sor2])\n",
    "        legend = plt.legend(['pre', 'act'],fontsize=20)\n",
    "        plt.xlabel('Number of data groups',fontsize=20)\n",
    "        plt.ylabel('NO concentration (ppm)',fontsize=20)\n",
    "        config = {\n",
    "        \"font.family\": 'Times New Roman', \n",
    "        }\n",
    "        rcParams.update(config)\n",
    "        plt.show()\n",
    "        result=np.c_[y_test[:,0][sor],y_test[:,1][sor1],y_test[:,2][sor2], outputs1[sor],outputs2[sor1],outputs3[sor2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc13766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9820fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x_test, y_test):\n",
    "    preds1 = []\n",
    "    preds2 = []\n",
    "    preds3 = [] \n",
    "    y_true1 = []\n",
    "    y_true2 = []\n",
    "    y_true3 = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_test = torch.Tensor(x_test).float()\n",
    "        y_test = torch.Tensor(y_test).float()\n",
    "        y_test = y_test.squeeze()\n",
    "        outputs1,outputs2,outputs3 = model(x_test) \n",
    "        detached_pred1 = outputs1.detach().cpu().numpy()\n",
    "        detached_pred2 = outputs2.detach().cpu().numpy()\n",
    "        detached_pred3 = outputs3.detach().cpu().numpy()\n",
    "        detached_label = y_test.detach().cpu().numpy()\n",
    "        for f in range(0, len(detached_label)):\n",
    "            preds1.append(detached_pred1[f])\n",
    "            preds2.append(detached_pred2[f])\n",
    "            preds3.append(detached_pred3[f])\n",
    "            y_true1.append(detached_label[f][0])\n",
    "            y_true2.append(detached_label[f][1])\n",
    "            y_true3.append(detached_label[f][2]) \n",
    "        mse = MK.mean_squared_error(y_true1, preds1)\n",
    "        r2 = MK.r2_score(y_true1, preds1)\n",
    "        print('SO2 MSE:',mse)\n",
    "        print('SO2 R2:',r2) \n",
    "        MSE = MK.mean_squared_error(y_true2, preds2)\n",
    "        R2 = MK.r2_score(y_true2, preds2)\n",
    "        print('CS2 MSE:',MSE)\n",
    "        print('CS2 R2:',R2)  \n",
    "        MMSE = MK.mean_squared_error(y_true3, preds3)\n",
    "        RR2 = MK.r2_score(y_true3, preds3)\n",
    "        print('NO MSE:',MMSE)\n",
    "        print('NO R2:',RR2)           \n",
    "        x_ = range(len(y_test))\n",
    "        plt.figure(figsize=(22,6))\n",
    "        plt.figure(1)\n",
    "        plt.plot(x_, outputs1)\n",
    "        plt.plot(x_,y_test[:,0])\n",
    "        legend = plt.legend(['pre', 'act'],fontsize=20)\n",
    "        plt.figure(2)\n",
    "        plt.plot(x_, outputs2)\n",
    "        plt.plot(x_,y_test[:,1])\n",
    "        legend = plt.legend(['pre', 'act'],fontsize=20)\n",
    "        plt.figure(3)\n",
    "        plt.plot(x_, outputs3)\n",
    "        plt.plot(x_,y_test[:,2])\n",
    "        legend = plt.legend(['pre', 'act'],fontsize=20)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3927b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f46dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
